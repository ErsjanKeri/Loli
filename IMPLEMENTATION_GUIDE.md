# üöÄ Pure Lambda Implementation Guide

## üìã **Step-by-Step Transformation**

### **Phase 1: Replace Current Video Processing (Day 1)**

#### **1.1 Remove Local Video Processor**
Completely delete the existing video_processor.py file since we're moving to pure Lambda processing. Update the Dockerfile to remove all Manim-related installations since video processing will happen in Lambda, not locally. Simplify docker-compose.yml to remove local video processing volumes and dependencies.

#### **1.2 Install AWS Dependencies**
Add boto3 and botocore to requirements.txt for AWS service integration. These are the core libraries needed to communicate with SQS, DynamoDB, and S3 from the FastAPI backend.

#### **1.3 Create Pure Lambda Processor**
```python
# app/services/lambda_video_processor.py
# (Use the complete implementation from AWS_LAMBDA_INTEGRATION.md)
```

#### **1.4 Update Configuration**
Replace the existing configuration with AWS-focused settings. Add all required AWS service configurations (credentials, region, resource names) while removing all local processing settings. The configuration should support both development (.env file) and production (environment variables) deployment patterns.

#### **1.5 Update Dependencies**
Replace the dependency injection to return the new Lambda video processor instead of the local one. This ensures all API endpoints automatically use the serverless processing approach.

#### **1.6 Update API Routes**
Modify the background video generation task to submit jobs to Lambda instead of processing locally. The task should generate the script using AI models, then immediately submit to SQS and update local storage with "queued for Lambda" status. Add new endpoints for checking Lambda job status via DynamoDB queries.

### **Phase 2: Deploy Lambda Infrastructure (Day 1-2)**

#### **2.1 Create Lambda Function**
Set up the directory structure for the Lambda function and layer. Create the main Lambda handler that processes Manim scripts, integrates with Polly for voiceover, and manages S3 uploads. Build the SAM template that defines all AWS resources needed.

#### **2.2 Deploy AWS Infrastructure**
Use AWS SAM CLI to build and deploy the complete serverless infrastructure. This creates the Lambda function, SQS queue, DynamoDB table, S3 bucket, and all necessary IAM permissions in a single deployment. The guided deployment process will prompt for configuration values.

#### **2.3 Update Environment Variables**
After deployment, SAM will output the resource identifiers (queue URLs, table names, bucket names) that need to be added to the FastAPI application's environment configuration. Update the .env file with these values to connect the backend to the Lambda infrastructure.

### **Phase 3: Test Pure Lambda Processing (Day 2)**

#### **3.1 Remove Docker Dependencies**
Simplify the Dockerfile to remove all Manim-related installations since video processing now happens in Lambda. The local Docker container only needs to run the FastAPI backend, so it becomes much lighter and faster to build.

#### **3.2 Update Docker Compose**
Remove all local video processing volumes and dependencies from docker-compose.yml. Add environment variables for AWS service configuration. The local container now only needs to connect to AWS services, not process videos locally.

#### **3.3 Test Lambda Integration**
Start the simplified API and test that video requests are properly submitted to Lambda. Verify that job status can be checked via DynamoDB and that completed videos can be downloaded from S3. This confirms the end-to-end serverless pipeline is working.

### **Phase 4: AWS Bedrock + Polly Integration (Day 2-3)**

#### **4.1 Replace Gemini with Bedrock**
Build AWS Bedrock integration service that can handle multiple AI models (Claude, Llama, Titan). Create an AI orchestrator that intelligently routes requests between Bedrock and OpenAI based on complexity and cost. This gives users choice and demonstrates multi-model capabilities.

#### **4.2 Add AWS Polly TTS**
Integrate AWS Polly to replace Azure TTS. Implement voice selection, SSML markup for natural speech, and integration with the Lambda video processing pipeline. This completes the AWS ecosystem integration.

#### **4.3 Update Script Generator**
Modify the existing script generator to use the new AI orchestrator instead of calling Gemini directly. This maintains the same interface while adding multi-model support behind the scenes.

### **Phase 5: Lovable React Frontend (Day 3-4)**

#### **5.1 Create React App with Lovable**
Use Lovable to build a modern, beautiful React application with key components for video creation, real-time status tracking, model selection, voice customization, and cost analytics. The interface should highlight the serverless architecture advantages and provide an impressive demo experience.

#### **5.2 API Integration**
Build a clean API client that connects the React frontend to the FastAPI backend. Implement real-time status polling to show Lambda processing progress, video gallery for completed videos, and analytics dashboard for cost and performance metrics.

## üéØ **Key Differences from Hybrid Approach**

### **What's REMOVED:**
- ‚ùå `app/services/video_processor.py` (entire file deleted)
- ‚ùå Local Manim installation in Docker
- ‚ùå Subprocess video processing
- ‚ùå Local file storage and temp directories
- ‚ùå Processing mode selection logic
- ‚ùå Fallback mechanisms
- ‚ùå Azure TTS integration

### **What's ADDED:**
- ‚úÖ `app/services/lambda_video_processor.py` (pure Lambda)
- ‚úÖ AWS Lambda function with Manim
- ‚úÖ SQS job queue
- ‚úÖ DynamoDB job tracking
- ‚úÖ S3 video storage
- ‚úÖ AWS Bedrock multi-model AI
- ‚úÖ AWS Polly TTS
- ‚úÖ CloudWatch monitoring

## üöÄ **Deployment Commands**

### **Complete Deployment**
```bash
# 1. Deploy AWS infrastructure
cd lambda/
sam build && sam deploy

# 2. Update environment variables
# (Add AWS credentials and resource URLs to .env)

# 3. Deploy API
cd ../app/
docker-compose up --build

# 4. Deploy React frontend (Lovable)
# (Use Lovable deployment process)
```

### **Environment Variables Checklist**
```bash
# Required for pure Lambda approach:
AWS_ACCESS_KEY_ID=xxx
AWS_SECRET_ACCESS_KEY=xxx
AWS_REGION=us-east-1
SQS_QUEUE_URL=xxx
DYNAMODB_JOBS_TABLE=xxx
S3_BUCKET_NAME=xxx

# AI Models
GEMINI_API_KEY=xxx  # For comparison
OPENAI_API_KEY=xxx  # For ChatGPT-5

# Remove these old variables:
# TEMP_DIR (Lambda handles)
# MAX_CONCURRENT_VIDEOS (Lambda auto-scales)
# AZURE_SUBSCRIPTION_KEY (replaced by Polly)
# AZURE_SERVICE_REGION (replaced by Polly)
```

## üèÜ **Success Validation**

### **How to Verify Pure Lambda Implementation:**
1. **No Local Processing**: Confirm `video_processor.py` is deleted
2. **Lambda Submission**: Videos go directly to SQS ‚Üí Lambda
3. **DynamoDB Tracking**: Status comes from DynamoDB, not local storage
4. **S3 Storage**: Videos stored in S3, not local files
5. **Infinite Scale**: Can submit 20+ videos simultaneously
6. **Zero Idle Cost**: No always-running video processing

### **Demo Readiness Checklist:**
- [ ] Submit 10+ videos simultaneously
- [ ] All process in parallel (not sequential)
- [ ] Real-time status from DynamoDB
- [ ] Videos download from S3
- [ ] CloudWatch shows Lambda executions
- [ ] Cost calculator shows $0 idle cost

**This pure Lambda approach is your hackathon winning strategy!** üöÄ
